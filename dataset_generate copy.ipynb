{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation Script\n",
    "\n",
    "This script performs the following operations:\n",
    "1. Extracts 5000 training questions and 100 testing questions for each domain (coding, math, trivia).\n",
    "2. Saves the selected datasets.\n",
    "3. Generates responses using 4 different teacher models via OpenRouter.\n",
    "4. Applies templates in half of the cases.\n",
    "5. Saves the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# from tqdm.notebook import tqdm # Causing ImportError with IProgress\n",
    "from tqdm import tqdm # Use standard tqdm instead\n",
    "from openai import OpenAI\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Ensure you have your OpenRouter API key set in your environment\n",
    "# os.environ[\"OPENROUTER_API_KEY\"] = \"sk-or-v1-...\"\n",
    "API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Please set OPENROUTER_API_KEY environment variable.\")\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "\n",
    "DOMAINS = [\"general\"]\n",
    "TEACHER_MODELS = [\n",
    "    \"qwen/qwen-2.5-72b-instruct\",\n",
    "    \"qwen/qwen-2.5-7b-instruct\",\n",
    "    \"meta-llama/llama-3.1-70b-instruct\",\n",
    "    \"meta-llama/llama-3.1-8b-instruct\",\n",
    "]\n",
    "TRAIN_SIZE = 5000\n",
    "TEST_SIZE = 100\n",
    "SEED = 42\n",
    "MAX_WORKERS = 5 # reduced per-config workers since we run configs in parallel\n",
    "MAX_PARALLEL_CONFIGS = 4 # Number of configurations to run simultaneously\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing OpenRouter connection...\n",
      "Connection successful!\n",
      "Response: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Testing OpenRouter connection...\")\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"meta-llama/llama-3.1-8b-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Hello, world!\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"Connection successful!\")\n",
    "    print(\"Response:\", completion.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(\"Connection failed:\", str(e))\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_select_data(domain, split, count):\n",
    "    \"\"\"\n",
    "    Loads data for a domain/split.\n",
    "    If 'selected' file exists, returns it.\n",
    "    Otherwise, samples from 'raw' file, saves to 'selected', and returns it.\n",
    "    \"\"\"\n",
    "    base_path = os.path.join(\"experiments\", domain)\n",
    "    selected_file = os.path.join(base_path, f\"{split}_selected.jsonl\")\n",
    "    raw_file = os.path.join(base_path, f\"{split}_raw.jsonl\")\n",
    "\n",
    "    # Check if selected file exists\n",
    "    if os.path.exists(selected_file):\n",
    "        print(f\"Loading existing selected data for {domain}/{split}...\")\n",
    "        with open(selected_file, 'r', encoding='utf-8') as f:\n",
    "            data = [json.loads(line) for line in f]\n",
    "        # Verify size (warn if mismatch, but allow reuse)\n",
    "        if len(data) != count:\n",
    "            print(f\"Warning: Existing file has {len(data)} items, expected {count}.\")\n",
    "        return data\n",
    "\n",
    "    print(f\"Sampling new data for {domain}/{split}...\")\n",
    "    # Load raw data\n",
    "    data = []\n",
    "    with open(raw_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if line.strip():\n",
    "                data.append(json.loads(line))\n",
    "\n",
    "    # Sample\n",
    "    random.seed(SEED)\n",
    "    if len(data) > count:\n",
    "        selected_data = random.sample(data, count)\n",
    "    else:\n",
    "        selected_data = data\n",
    "\n",
    "    # Save selected\n",
    "    with open(selected_file, 'w', encoding='utf-8') as f:\n",
    "        for item in selected_data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "    return selected_data\n",
    "\n",
    "def load_template(domain):\n",
    "    path = os.path.join(\"experiments\", domain, \"template.txt\")\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_response(item, model, template_text, use_template):\n",
    "    \"\"\"\n",
    "    Generates a response for a single item.\n",
    "    Returns the enriched item with 'response', 'model', 'template_applied'.\n",
    "    \"\"\"\n",
    "    question = item['question']\n",
    "\n",
    "    if use_template and template_text:\n",
    "        # Assume template has [QUESTION] placeholder based on file inspection\n",
    "        prompt = template_text.replace(\"[QUESTION]\", question)\n",
    "    else:\n",
    "        prompt = question\n",
    "\n",
    "    # Retry logic\n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            )\n",
    "            response = completion.choices[0].message.content\n",
    "\n",
    "            result = item.copy()\n",
    "            result['response'] = response\n",
    "            result['model'] = model\n",
    "            result['template_applied'] = use_template\n",
    "            result['prompt'] = prompt\n",
    "            return result\n",
    "\n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"Failed to generate for prompt: {prompt[:50]}... Error: {e}\")\n",
    "                result = item.copy()\n",
    "                result['error'] = str(e)\n",
    "                return result\n",
    "            time.sleep(2 ** attempt)  # Exponential backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_generation_process(domain, split, data, model, use_template):\n",
    "    \"\"\"\n",
    "    Runs generation for a specific configuration and saves results.\n",
    "    \"\"\"\n",
    "    template_text = load_template(domain)\n",
    "\n",
    "    # Construct output filename\n",
    "    # Format: experiments/{domain}/{split}_generated_{model_clean}_{template}.jsonl\n",
    "    model_clean = model.replace(\"/\", \"_\")\n",
    "    template_str = \"with_template\" if use_template else \"no_template\"\n",
    "    output_filename = f\"{split}_generated_{model_clean}_{template_str}.jsonl\"\n",
    "    output_path = os.path.join(\"experiments\", domain, output_filename)\n",
    "\n",
    "    if os.path.exists(output_path):\n",
    "        print(f\"  [Skipping] {output_filename} already exists.\")\n",
    "        return\n",
    "\n",
    "    print(f\"  [Generating] {domain} | {split} | {model} | Template={use_template}\")\n",
    "\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = [\n",
    "            executor.submit(generate_single_response, item, model, template_text, use_template)\n",
    "            for item in data\n",
    "        ]\n",
    "\n",
    "        # Using tqdm for progress within the generation\n",
    "        for future in tqdm(as_completed(futures), total=len(data), desc=f\"    Progress\", leave=False):\n",
    "            results.append(future.result())\n",
    "\n",
    "    # Save results\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for res in results:\n",
    "            f.write(json.dumps(res, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"  [Saved] {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for trivia...\n",
      "Loading existing selected data for trivia/train...\n",
      "Loading existing selected data for trivia/test...\n",
      "\n",
      "Total configurations to run: 8\n",
      "Starting parallel execution...\n",
      "  [Skipping] train_generated_qwen_qwen-2.5-72b-instruct_with_template.jsonl already exists.\n",
      "  [Skipping] test_generated_qwen_qwen-2.5-72b-instruct_with_template.jsonl already exists.\n",
      "Success: trivia qwen/qwen-2.5-72b-instruct\n",
      "Success: trivia qwen/qwen-2.5-72b-instruct\n",
      "  [Skipping] test_generated_qwen_qwen-2.5-72b-instruct_no_template.jsonl already exists.\n",
      "Success: trivia qwen/qwen-2.5-72b-instruct\n",
      "  [Skipping] train_generated_qwen_qwen-2.5-7b-instruct_with_template.jsonl already exists.\n",
      "  [Skipping] test_generated_qwen_qwen-2.5-7b-instruct_with_template.jsonl already exists.\n",
      "  [Generating] trivia | train | qwen/qwen-2.5-72b-instruct | Template=False\n",
      "Success: trivia qwen/qwen-2.5-7b-instruct\n",
      "Success: trivia qwen/qwen-2.5-7b-instruct\n",
      "  [Skipping] test_generated_qwen_qwen-2.5-7b-instruct_no_template.jsonl already exists.\n",
      "Success: trivia qwen/qwen-2.5-7b-instruct\n",
      "  [Generating] trivia | train | qwen/qwen-2.5-7b-instruct | Template=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Saved] train_generated_qwen_qwen-2.5-7b-instruct_no_template.jsonl\n",
      "Success: trivia qwen/qwen-2.5-7b-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [Saved] train_generated_qwen_qwen-2.5-72b-instruct_no_template.jsonl\n",
      "Success: trivia qwen/qwen-2.5-72b-instruct\n",
      "\n",
      "All generation tasks completed!\n"
     ]
    }
   ],
   "source": [
    "# --- Main Execution Loop ---\n",
    "\n",
    "# Pre-load all data serially to avoid race conditions\n",
    "domain_data = {}\n",
    "for domain in DOMAINS:\n",
    "    print(f\"Loading data for {domain}...\")\n",
    "    try:\n",
    "        train_data = load_and_select_data(domain, \"train\", TRAIN_SIZE)\n",
    "        test_data = load_and_select_data(domain, \"test\", TEST_SIZE)\n",
    "        domain_data[domain] = {\"train\": train_data, \"test\": test_data}\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping domain {domain} due to error: {e}\")\n",
    "\n",
    "# Collect all tasks\n",
    "tasks = []\n",
    "for domain, datasets in domain_data.items():\n",
    "    for model in TEACHER_MODELS:\n",
    "        for use_template in [True, False]:\n",
    "            for split_name in [\"train\", \"test\"]:\n",
    "                tasks.append({\n",
    "                    \"domain\": domain,\n",
    "                    \"split\": split_name,\n",
    "                    \"data\": datasets[split_name],\n",
    "                    \"model\": model,\n",
    "                    \"use_template\": use_template\n",
    "                })\n",
    "\n",
    "print(f\"\\nTotal configurations to run: {len(tasks)}\")\n",
    "\n",
    "def process_task(task):\n",
    "    try:\n",
    "        run_generation_process(\n",
    "            domain=task[\"domain\"],\n",
    "            split=task[\"split\"],\n",
    "            data=task[\"data\"],\n",
    "            model=task[\"model\"],\n",
    "            use_template=task[\"use_template\"]\n",
    "        )\n",
    "        return f\"Success: {task['domain']} {task['model']}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error in {task['domain']} {task['model']}: {e}\"\n",
    "\n",
    "print(\"Starting parallel execution...\")\n",
    "with ThreadPoolExecutor(max_workers=MAX_PARALLEL_CONFIGS) as executor:\n",
    "    futures = [executor.submit(process_task, task) for task in tasks]\n",
    "\n",
    "    for future in as_completed(futures):\n",
    "        print(future.result())\n",
    "\n",
    "print(\"\\nAll generation tasks completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
